#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ Redis –∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –Ω–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∞–Ω–∫–µ—Ç –≤ CSV —Ñ–æ—Ä–º–∞—Ç–µ.
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç FSM —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ Redis –∏ –¥–∞–Ω–Ω—ã–µ –∏–∑ PostgreSQL.
"""

import asyncio
import csv
import json
import logging
import os
import sys
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any

import asyncpg
import redis.asyncio as redis
from environs import Env

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config.config import load_config
from app.infrastructure.database.models.applications import ApplicationsModel

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class RedisConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Redis"""
    def __init__(self, host: str = "localhost", port: int = 6379, password: str = None, db: int = 0):
        self.host = host
        self.port = port
        self.password = password
        self.db = db


class IncompleteApplicationsAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∞–Ω–∫–µ—Ç"""
    
    def __init__(self, redis_config: RedisConfig, postgres_config: Dict[str, Any]):
        self.redis_config = redis_config
        self.postgres_config = postgres_config
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª—è –∞–Ω–∫–µ—Ç—ã –∏ –∏—Ö –≤–∞–∂–Ω–æ—Å—Ç—å
        self.application_fields = {
            'full_name': '–§–ò–û',
            'university': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç',
            'course': '–ö—É—Ä—Å',
            'phone': '–¢–µ–ª–µ—Ñ–æ–Ω',
            'email': 'Email',
            'how_found_kbk': '–ö–∞–∫ —É–∑–Ω–∞–ª –æ –ö–ë–ö',
            'experience': '–û–ø—ã—Ç',
            'motivation': '–ú–æ—Ç–∏–≤–∞—Ü–∏—è',
            'resume_local_path': '–†–µ–∑—é–º–µ',
            'previous_department': '–ü—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç–¥–µ–ª',
            'department_1': '–û—Ç–¥–µ–ª 1 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
            'position_1': '–ü–æ–∑–∏—Ü–∏—è 1 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
            'subdepartment_1': '–ü–æ–¥–æ—Ç–¥–µ–ª 1 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
            'department_2': '–û—Ç–¥–µ–ª 2 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
            'position_2': '–ü–æ–∑–∏—Ü–∏—è 2 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
            'subdepartment_2': '–ü–æ–¥–æ—Ç–¥–µ–ª 2 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
            'department_3': '–û—Ç–¥–µ–ª 3 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
            'position_3': '–ü–æ–∑–∏—Ü–∏—è 3 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
            'subdepartment_3': '–ü–æ–¥–æ—Ç–¥–µ–ª 3 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç',
        }
        
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–π –∞–Ω–∫–µ—Ç—ã
        self.required_fields = {
            'full_name', 'university', 'course', 'phone', 'email', 
            'how_found_kbk', 'experience', 'motivation', 'resume_local_path',
            'department_1', 'position_1'
        }

    async def connect_to_redis(self) -> redis.Redis:
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis"""
        try:
            redis_client = redis.Redis(
                host=self.redis_config.host,
                port=self.redis_config.port,
                password=self.redis_config.password,
                db=self.redis_config.db,
                decode_responses=True
            )
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
            await redis_client.ping()
            logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω –∫ Redis: {self.redis_config.host}:{self.redis_config.port}")
            return redis_client
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Redis: {e}")
            raise

    async def connect_to_postgres(self) -> asyncpg.Connection:
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL"""
        try:
            conn = await asyncpg.connect(
                user=self.postgres_config['user'],
                password=self.postgres_config['password'],
                database=self.postgres_config['database'],
                host=self.postgres_config['host'],
                port=self.postgres_config['port']
            )
            logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω –∫ PostgreSQL: {self.postgres_config['host']}:{self.postgres_config['port']}")
            return conn
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL: {e}")
            raise

    async def get_fsm_data(self, redis_client: redis.Redis) -> Dict[str, Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö FSM –∏–∑ Redis"""
        fsm_data = {}
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–ª—é—á–∏ FSM —Å–æ—Å—Ç–æ—è–Ω–∏–π
            # –§–æ—Ä–º–∞—Ç –∫–ª—é—á–µ–π: fsm:{bot_id}:{user_id}:state –∏–ª–∏ fsm:{bot_id}:{user_id}:data
            fsm_keys = await redis_client.keys("fsm:*")
            
            user_states = {}
            user_data = {}
            
            for key in fsm_keys:
                parts = key.split(':')
                if len(parts) >= 4:
                    user_id = parts[2]
                    key_type = parts[3]
                    
                    if key_type == 'state':
                        state_value = await redis_client.get(key)
                        if state_value:
                            user_states[user_id] = state_value
                    elif key_type == 'data':
                        data_value = await redis_client.get(key)
                        if data_value:
                            try:
                                user_data[user_id] = json.loads(data_value)
                            except json.JSONDecodeError:
                                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å JSON –¥–ª—è –∫–ª—é—á–∞ {key}")
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –¥–∞–Ω–Ω—ã–µ
            for user_id in set(list(user_states.keys()) + list(user_data.keys())):
                fsm_data[user_id] = {
                    'state': user_states.get(user_id),
                    'data': user_data.get(user_id, {})
                }
            
            logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ FSM –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(fsm_data)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
            return fsm_data
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è FSM –¥–∞–Ω–Ω—ã—Ö: {e}")
            return {}

    async def get_applications_from_db(self, postgres_conn: asyncpg.Connection) -> Dict[int, ApplicationsModel]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞—è–≤–æ–∫ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            query = """
            SELECT id, user_id, created, updated, full_name, university, course, phone, email, 
                   telegram_username, how_found_kbk, department_1, position_1, subdepartment_1,
                   department_2, position_2, subdepartment_2, department_3, position_3, subdepartment_3,
                   experience, motivation, resume_local_path, resume_google_drive_url, previous_department
            FROM applications
            ORDER BY created DESC;
            """
            
            rows = await postgres_conn.fetch(query)
            applications = {}
            
            for row in rows:
                app = ApplicationsModel(
                    id=row['id'],
                    user_id=row['user_id'],
                    created=row['created'],
                    updated=row['updated'],
                    full_name=row['full_name'],
                    university=row['university'],
                    course=row['course'],
                    phone=row['phone'],
                    email=row['email'],
                    telegram_username=row['telegram_username'],
                    how_found_kbk=row['how_found_kbk'],
                    department_1=row['department_1'],
                    position_1=row['position_1'],
                    subdepartment_1=row['subdepartment_1'],
                    department_2=row['department_2'],
                    position_2=row['position_2'],
                    subdepartment_2=row['subdepartment_2'],
                    department_3=row['department_3'],
                    position_3=row['position_3'],
                    subdepartment_3=row['subdepartment_3'],
                    experience=row['experience'],
                    motivation=row['motivation'],
                    resume_local_path=row['resume_local_path'],
                    resume_google_drive_url=row['resume_google_drive_url'],
                    previous_department=row['previous_department']
                )
                applications[app.user_id] = app
            
            logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(applications)} –∑–∞—è–≤–æ–∫ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
            return applications
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞—è–≤–æ–∫ –∏–∑ –ë–î: {e}")
            return {}

    def analyze_completion_status(self, application: ApplicationsModel) -> Tuple[bool, List[str], float]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –∞–Ω–∫–µ—Ç—ã"""
        missing_fields = []
        filled_fields = 0
        total_fields = len(self.application_fields)
        
        for field_name in self.application_fields:
            value = getattr(application, field_name, None)
            if value is None or (isinstance(value, str) and value.strip() == ""):
                missing_fields.append(self.application_fields[field_name])
            else:
                filled_fields += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        missing_required = []
        for field in self.required_fields:
            value = getattr(application, field, None)
            if value is None or (isinstance(value, str) and value.strip() == ""):
                missing_required.append(self.application_fields[field])
        
        is_complete = len(missing_required) == 0
        completion_percentage = (filled_fields / total_fields) * 100
        
        return is_complete, missing_fields, completion_percentage

    def get_state_description(self, state: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è FSM"""
        state_descriptions = {
            # FirstStageSG —Å–æ—Å—Ç–æ—è–Ω–∏—è
            "FirstStageSG:stage_info": "–ü—Ä–æ—Å–º–æ—Ç—Ä –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–µ—Ä–≤–æ–º —ç—Ç–∞–ø–µ",
            "FirstStageSG:full_name": "–í–≤–æ–¥ –§–ò–û",
            "FirstStageSG:university": "–í–≤–æ–¥ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞",
            "FirstStageSG:course": "–í–≤–æ–¥ –∫—É—Ä—Å–∞",
            "FirstStageSG:phone": "–í–≤–æ–¥ —Ç–µ–ª–µ—Ñ–æ–Ω–∞",
            "FirstStageSG:email": "–í–≤–æ–¥ email",
            "FirstStageSG:how_found_kbk": "–í—ã–±–æ—Ä –∫–∞–∫ —É–∑–Ω–∞–ª –æ –ö–ë–ö",
            "FirstStageSG:previous_department": "–í—ã–±–æ—Ä –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–¥–µ–ª–∞",
            "FirstStageSG:experience": "–í–≤–æ–¥ –æ–ø—ã—Ç–∞",
            "FirstStageSG:motivation": "–í–≤–æ–¥ –º–æ—Ç–∏–≤–∞—Ü–∏–∏",
            "FirstStageSG:resume_upload": "–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—é–º–µ",
            "FirstStageSG:confirmation": "–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∞–Ω–∫–µ—Ç—ã",
            "FirstStageSG:edit_menu": "–ú–µ–Ω—é —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
            "FirstStageSG:success": "–ê–Ω–∫–µ—Ç–∞ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞",
            
            # JobSelectionSG —Å–æ—Å—Ç–æ—è–Ω–∏—è
            "JobSelectionSG:select_department": "–í—ã–±–æ—Ä –æ—Ç–¥–µ–ª–∞ (1 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)",
            "JobSelectionSG:select_subdepartment": "–í—ã–±–æ—Ä –ø–æ–¥–æ—Ç–¥–µ–ª–∞ (1 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)",
            "JobSelectionSG:select_position": "–í—ã–±–æ—Ä –ø–æ–∑–∏—Ü–∏–∏ (1 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)",
            "JobSelectionSG:select_department_2": "–í—ã–±–æ—Ä –æ—Ç–¥–µ–ª–∞ (2 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)",
            "JobSelectionSG:select_subdepartment_2": "–í—ã–±–æ—Ä –ø–æ–¥–æ—Ç–¥–µ–ª–∞ (2 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)",
            "JobSelectionSG:select_position_2": "–í—ã–±–æ—Ä –ø–æ–∑–∏—Ü–∏–∏ (2 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)",
            "JobSelectionSG:select_department_3": "–í—ã–±–æ—Ä –æ—Ç–¥–µ–ª–∞ (3 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)",
            "JobSelectionSG:select_subdepartment_3": "–í—ã–±–æ—Ä –ø–æ–¥–æ—Ç–¥–µ–ª–∞ (3 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)",
            "JobSelectionSG:select_position_3": "–í—ã–±–æ—Ä –ø–æ–∑–∏—Ü–∏–∏ (3 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)",
            "JobSelectionSG:priorities_overview": "–û–±–∑–æ—Ä –≤—Å–µ—Ö –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤",
            "JobSelectionSG:complete_selection": "–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∞",
        }
        
        return state_descriptions.get(state, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {state}")

    async def generate_csv_report(self, analysis_data: List[Dict], filename: str = None):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è CSV –æ—Ç—á–µ—Ç–∞"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"incomplete_applications_{timestamp}.csv"
        
        try:
            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = [
                    'user_id', 'telegram_username', 'full_name', 'email', 'phone',
                    'current_state', 'state_description', 'in_database', 'is_complete',
                    'completion_percentage', 'missing_fields', 'last_updated', 'created'
                ]
                
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for data in analysis_data:
                    writer.writerow(data)
            
            logger.info(f"CSV –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
            print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {filename}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è CSV –æ—Ç—á–µ—Ç–∞: {e}")
            raise

    async def analyze_applications(self, redis_config: RedisConfig = None) -> List[Dict]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞—è–≤–æ–∫"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é Redis –∏–ª–∏ —Ç–µ–∫—É—â—É—é
        if redis_config:
            self.redis_config = redis_config
            
        redis_client = None
        postgres_conn = None
        
        try:
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Redis –∏ PostgreSQL
            redis_client = await self.connect_to_redis()
            postgres_conn = await self.connect_to_postgres()
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            fsm_data = await self.get_fsm_data(redis_client)
            applications = await self.get_applications_from_db(postgres_conn)
            
            analysis_results = []
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ FSM
            for user_id_str, fsm_info in fsm_data.items():
                try:
                    user_id = int(user_id_str)
                except ValueError:
                    logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π user_id: {user_id_str}")
                    continue
                
                application = applications.get(user_id)
                current_state = fsm_info.get('state')
                fsm_user_data = fsm_info.get('data', {})
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
                if application:
                    is_complete, missing_fields, completion_percentage = self.analyze_completion_status(application)
                    in_database = True
                    last_updated = application.updated.isoformat() if application.updated else None
                    created = application.created.isoformat() if application.created else None
                    full_name = application.full_name
                    email = application.email
                    phone = application.phone
                    telegram_username = application.telegram_username
                else:
                    is_complete = False
                    missing_fields = list(self.application_fields.values())
                    completion_percentage = 0.0
                    in_database = False
                    last_updated = None
                    created = None
                    full_name = fsm_user_data.get('full_name')
                    email = fsm_user_data.get('email')
                    phone = fsm_user_data.get('phone')
                    telegram_username = fsm_user_data.get('telegram_username')
                
                analysis_results.append({
                    'user_id': user_id,
                    'telegram_username': telegram_username or '–ù–µ —É–∫–∞–∑–∞–Ω',
                    'full_name': full_name or '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
                    'email': email or '–ù–µ —É–∫–∞–∑–∞–Ω',
                    'phone': phone or '–ù–µ —É–∫–∞–∑–∞–Ω',
                    'current_state': current_state or '–ù–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è',
                    'state_description': self.get_state_description(current_state) if current_state else '–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è',
                    'in_database': '–î–∞' if in_database else '–ù–µ—Ç',
                    'is_complete': '–î–∞' if is_complete else '–ù–µ—Ç',
                    'completion_percentage': f"{completion_percentage:.1f}%",
                    'missing_fields': '; '.join(missing_fields) if missing_fields else '–í—Å–µ –ø–æ–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω—ã',
                    'last_updated': last_updated or '–ù–µ –æ–±–Ω–æ–≤–ª—è–ª–æ—Å—å',
                    'created': created or '–ù–µ —Å–æ–∑–¥–∞–Ω–æ'
                })
            
            # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –ë–î, –Ω–æ –Ω–µ—Ç –≤ FSM (–∑–∞–≤–µ—Ä—à–∏–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å)
            for user_id, application in applications.items():
                if str(user_id) not in fsm_data:
                    is_complete, missing_fields, completion_percentage = self.analyze_completion_status(application)
                    
                    analysis_results.append({
                        'user_id': user_id,
                        'telegram_username': application.telegram_username or '–ù–µ —É–∫–∞–∑–∞–Ω',
                        'full_name': application.full_name or '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
                        'email': application.email or '–ù–µ —É–∫–∞–∑–∞–Ω',
                        'phone': application.phone or '–ù–µ —É–∫–∞–∑–∞–Ω',
                        'current_state': '–ó–∞–≤–µ—Ä—à–µ–Ω',
                        'state_description': '–ü—Ä–æ—Ü–µ—Å—Å –ø–æ–¥–∞—á–∏ –∑–∞—è–≤–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω',
                        'in_database': '–î–∞',
                        'is_complete': '–î–∞' if is_complete else '–ù–µ—Ç',
                        'completion_percentage': f"{completion_percentage:.1f}%",
                        'missing_fields': '; '.join(missing_fields) if missing_fields else '–í—Å–µ –ø–æ–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω—ã',
                        'last_updated': application.updated.isoformat() if application.updated else '–ù–µ –æ–±–Ω–æ–≤–ª—è–ª–æ—Å—å',
                        'created': application.created.isoformat() if application.created else '–ù–µ —Å–æ–∑–¥–∞–Ω–æ'
                    })
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è (–Ω–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —Å–Ω–∞—á–∞–ª–∞)
            analysis_results.sort(key=lambda x: (
                x['is_complete'] == '–î–∞',  # –ù–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —Å–Ω–∞—á–∞–ª–∞
                -float(x['completion_percentage'].rstrip('%'))  # –ü–æ —É–±—ã–≤–∞–Ω–∏—é –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
            ))
            
            return analysis_results
            
        finally:
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            if redis_client:
                await redis_client.aclose()
            if postgres_conn:
                await postgres_conn.close()

    def print_summary(self, analysis_data: List[Dict]):
        """–í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–π —Å–≤–æ–¥–∫–∏"""
        total_users = len(analysis_data)
        incomplete_users = len([d for d in analysis_data if d['is_complete'] == '–ù–µ—Ç'])
        users_in_db = len([d for d in analysis_data if d['in_database'] == '–î–∞'])
        users_in_fsm = len([d for d in analysis_data if d['current_state'] != '–ó–∞–≤–µ—Ä—à–µ–Ω'])
        
        print("\n" + "="*60)
        print("üìä –°–í–û–î–ö–ê –ê–ù–ê–õ–ò–ó–ê –ù–ï–ó–ê–ü–û–õ–ù–ï–ù–ù–´–• –ê–ù–ö–ï–¢")
        print("="*60)
        print(f"üë• –í—Å–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {total_users}")
        print(f"‚ùå –ù–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∞–Ω–∫–µ—Ç: {incomplete_users}")
        print(f"‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö: {total_users - incomplete_users}")
        print(f"üíæ –ó–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {users_in_db}")
        print(f"üîÑ –ê–∫—Ç–∏–≤–Ω—ã—Ö –≤ FSM: {users_in_fsm}")
        print("="*60)
        
        if incomplete_users > 0:
            print(f"\nüîç –¢–û–ü-5 –ù–ï–ó–ê–ü–û–õ–ù–ï–ù–ù–´–• –ê–ù–ö–ï–¢:")
            incomplete_only = [d for d in analysis_data if d['is_complete'] == '–ù–µ—Ç'][:5]
            for i, data in enumerate(incomplete_only, 1):
                print(f"{i}. User ID: {data['user_id']} | {data['full_name']} | {data['completion_percentage']} | {data['state_description']}")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∞–Ω–∫–µ—Ç –ö–ë–ö")
    print("="*50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    try:
        config = load_config()
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è PostgreSQL –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        postgres_config = {
            'user': config.db_applications.user,
            'password': config.db_applications.password,
            'database': config.db_applications.database,
            'host': config.db_applications.host,
            'port': config.db_applications.port
        }
        
        # –õ–æ–∫–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Redis –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        local_redis_config = RedisConfig(
            host="localhost",
            port=6379,
            password=None,  # –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ Redis –æ–±—ã—á–Ω–æ –Ω–µ—Ç –ø–∞—Ä–æ–ª—è
            db=0
        )
        
        # –£–¥–∞–ª–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Redis (–∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
        remote_redis_config = RedisConfig(
            host="45.90.217.194",
            port=6380,
            password=config.redis.password,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–æ–ª—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            db=0
        )
        
        analyzer = IncompleteApplicationsAnalyzer(local_redis_config, postgres_config)
        
        print("üîÑ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É Redis –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π Redis
        try:
            analysis_results = await analyzer.analyze_applications(local_redis_config)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            local_filename = f"incomplete_applications_local_{timestamp}.csv"
            await analyzer.generate_csv_report(analysis_results, local_filename)
            
            # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
            analyzer.print_summary(analysis_results)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ Redis: {e}")
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ Redis: {e}")
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É–¥–∞–ª–µ–Ω–Ω—ã–π Redis
        print(f"\n{'='*50}")
        choice = input("üåê –•–æ—Ç–∏—Ç–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —É–¥–∞–ª–µ–Ω–Ω—ã–π Redis (45.90.217.194:6380)? (y/N): ").lower()
        
        if choice in ['y', 'yes', '–¥–∞']:
            print("üîÑ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —É–¥–∞–ª–µ–Ω–Ω–æ–º—É Redis –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö...")
            try:
                analysis_results_remote = await analyzer.analyze_applications(remote_redis_config)
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ Redis
                remote_filename = f"incomplete_applications_remote_{timestamp}.csv"
                await analyzer.generate_csv_report(analysis_results_remote, remote_filename)
                
                # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
                print("\n" + "="*60)
                print("üìä –°–í–û–î–ö–ê –î–õ–Ø –£–î–ê–õ–ï–ù–ù–û–ì–û REDIS")
                analyzer.print_summary(analysis_results_remote)
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ Redis: {e}")
                logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ Redis: {e}")
        
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
